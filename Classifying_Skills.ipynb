{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Major1-Akshara.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoFPz3R07BDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cc9f78-d597-4eec-f6d1-bf21c67fa607"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woK3SvTpZZw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7b8a7b-aad2-4f57-9fb5-ce26c15eeeaa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBtsxYSsw6ZM"
      },
      "source": [
        "def cleanResume(resumeText):\n",
        "\n",
        "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
        "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
        "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
        "    return resumeText"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2L440xhxESt"
      },
      "source": [
        "def getData():\n",
        "\n",
        "  resumeDataSet = pd.read_csv('/content/drive/My Drive/new_dataset_of_resume_skills.csv')\n",
        "\n",
        "  resumeDataSet['cleaned_resume_skills'] = ''\n",
        "  resumeDataSet['cleaned_resume_skills'] = resumeDataSet.Resume.apply(lambda x: cleanResume(x))\n",
        "  \n",
        "  return resumeDataSet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybEzwP2alzUf"
      },
      "source": [
        "def encoding(resumeDataSet):\n",
        "  \n",
        "  le = LabelEncoder()    \n",
        "  resumeDataSet['Category'] = le.fit_transform(resumeDataSet['Category'])\n",
        "  return le"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTsDJQglmUSD"
      },
      "source": [
        "def vectorizing(requiredText):\n",
        "\n",
        "  word_vectorizer = TfidfVectorizer( sublinear_tf=True, stop_words='english')\n",
        "  word_vectorizer.fit(requiredText)\n",
        "  WordFeatures = word_vectorizer.transform(requiredText)\n",
        "\n",
        "  return word_vectorizer, WordFeatures"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnQutAXoq7iM"
      },
      "source": [
        "def trainModel(X,Y):\n",
        "\n",
        "  x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=4,test_size=0.25)\n",
        "\n",
        "  model = KNeighborsClassifier(n_neighbors=10).fit(x_train, y_train)\n",
        "  prediction = model.predict(x_test)\n",
        "  print('Accuracy of KNN :- {:.2f}'.format(model.score(x_test, y_test)))\n",
        "  return model\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYn64QqfNopd"
      },
      "source": [
        "def topKNeighbours(y, model, testData, le,k=2):\n",
        "\n",
        "  top_k = set()     # Set of unique Neighbours\n",
        "  i = 1             # Predicted value will always be added to the set\n",
        "\n",
        "  predictedValue = model.predict(testData)\n",
        "  invrValue = le.inverse_transform(predictedValue)[0]\n",
        "  # print(invrValue)\n",
        "  top_k.add(invrValue)\n",
        "  \n",
        "  dist, ind = model.kneighbors(testData)\n",
        "  # print(dist[0])\n",
        "  # print(ind[0])\n",
        "\n",
        "  for i in range(k-1) :\n",
        "      top_k.add(y[ind[0][i]])\n",
        "  \n",
        "  return top_k\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiexfTnQfHHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5a4792-7fb7-43e1-a80a-b949cfec67c4"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # Get data\n",
        "  resumeDataSet = getData()  \n",
        "\n",
        "  # Y == Categories without encoding\n",
        "  y = resumeDataSet['Category']\n",
        "\n",
        "  # Cleaned Resume values\n",
        "  reqText = resumeDataSet['cleaned_resume_skills'].values\n",
        "\n",
        "  # Encoding the Categories\n",
        "  le = encoding(resumeDataSet)\n",
        "\n",
        "  # The encoded required category values\n",
        "  reqTarget = resumeDataSet['Category'].values\n",
        "\n",
        "  # For TF-IDF\n",
        "  wordVec, wordFeatures = vectorizing(reqText)\n",
        "\n",
        "  # Returning the trained model\n",
        "  knn = trainModel(wordFeatures,reqTarget)\n",
        "\n",
        "  testData = ['''Big Data, Nosql, MongoDB, Database, Redis''']\n",
        "  cleanTestData = [x.lower() for x in testData]\n",
        " \n",
        "  # Transforming the test data to vector form\n",
        "  wordFeatures_testData = wordVec.transform(cleanTestData)\n",
        "\n",
        "  # Top K categories\n",
        "  topK = topKNeighbours(y,knn,wordFeatures_testData,le)\n",
        "  print(topK)\n",
        "  "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of KNN :- 0.74\n",
            "{'Database', 'SAP Developer'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neVLBLxzteGi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}