{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Major1-Akshara.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoFPz3R07BDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b415a4-bbe3-49b9-cf59-5a33c8b6d136"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woK3SvTpZZw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817c915a-3b11-4173-fcab-70972eba98a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBtsxYSsw6ZM"
      },
      "source": [
        "def cleanResume(resumeText):\n",
        "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"$%&'()*,-/:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
        "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
        "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
        "    return resumeText"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2L440xhxESt"
      },
      "source": [
        "def getData():\n",
        "\n",
        "  resumeDataSet = pd.read_csv('/content/drive/My Drive/new_dataset_of_resume_skills1.csv')\n",
        "  resumeDataSet['cleaned_resume_skills'] = ''\n",
        "  resumeDataSet['cleaned_resume_skills'] = resumeDataSet.Resume.apply(lambda x: cleanResume(x.lower()))\n",
        "  \n",
        "  return resumeDataSet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybEzwP2alzUf"
      },
      "source": [
        "# def encoding(resumeDataSet):\n",
        "  \n",
        "#   le = LabelEncoder()    \n",
        "#   resumeDataSet['Category'] = le.fit_transform(resumeDataSet['Category'])\n",
        "#   joblib.dump(le,'/content/drive/My Drive/labelEncoder.pkl')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTsDJQglmUSD"
      },
      "source": [
        "# def vectorizing(requiredText):\n",
        "\n",
        "#   word_vectorizer = TfidfVectorizer( sublinear_tf=True, stop_words='english')\n",
        "#   word_vectorizer.fit(requiredText)\n",
        "#   WordFeatures = word_vectorizer.transform(requiredText)\n",
        "\n",
        "#   joblib.dump(word_vectorizer,'/content/drive/My Drive/wordVectorizer.pkl')\n",
        "#   return WordFeatures\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnQutAXoq7iM"
      },
      "source": [
        "# def trainModel(X,Y):\n",
        "\n",
        "#   x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=4,test_size=0.25)\n",
        "\n",
        "#   model = KNeighborsClassifier(n_neighbors=6).fit(x_train, y_train)\n",
        "#   prediction = model.predict(x_test)\n",
        "#   print('Accuracy of KNN :- {:.2f}'.format(model.score(x_test, y_test)))\n",
        "#   joblib.dump(model,'/content/drive/My Drive/knn.pkl')\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYn64QqfNopd"
      },
      "source": [
        "def topKNeighbours(y, testData,k=3):\n",
        "\n",
        "  model = joblib.load('/content/drive/My Drive/knn.pkl')\n",
        "  le = joblib.load('/content/drive/My Drive/labelEncoder.pkl')\n",
        "\n",
        "  top_k = set()     # Set of unique Neighbours\n",
        "  i = 1             # Predicted value will always be added to the set\n",
        "\n",
        "  predictedValue = model.predict(testData)\n",
        "  invrValue = le.inverse_transform(predictedValue)[0]\n",
        "  \n",
        "  top_k.add(invrValue)\n",
        "  dist, ind = model.kneighbors(testData)\n",
        "  # print(dist[0])\n",
        "  # print(ind[0])\n",
        "\n",
        "  for i in range(k-1) :\n",
        "      top_k.add(y[ind[0][i]])\n",
        "  \n",
        "  return top_k\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiexfTnQfHHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bae460-91ad-46cc-a5c4-23cce6ab1ef8"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # Get data\n",
        "  resumeDataSet = getData()  \n",
        "\n",
        "  # Y == Categories without encoding\n",
        "  y = resumeDataSet['Category']\n",
        "  \n",
        "  # # Cleaned Resume values\n",
        "  # reqText = resumeDataSet['cleaned_resume_skills'].values\n",
        "  \n",
        "  # # Encoding the Categories\n",
        "  # encoding(resumeDataSet)\n",
        "\n",
        "  # # The encoded required category values\n",
        "  # reqTarget = resumeDataSet['Category'].values\n",
        "\n",
        "  # # For TF-IDF\n",
        "  # wordFeatures = vectorizing(reqText)\n",
        "\n",
        "  # # Training the model\n",
        "  # trainModel(wordFeatures,reqTarget)\n",
        "\n",
        "  testData = ['Angularjs, Python, JIRA, keras, Jenkins ']\n",
        "  cleanTestData = [x.lower() for x in testData]\n",
        " \n",
        "  # Transforming the test data to vector form\n",
        "  wordVec = joblib.load('/content/drive/My Drive/wordVectorizer.pkl')\n",
        "  wordFeatures_testData = wordVec.transform(cleanTestData)\n",
        "\n",
        "  # Top K categories\n",
        "  topK = topKNeighbours(y,wordFeatures_testData)\n",
        "  print(topK)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Data Science', 'HR', 'DevOps Engineer'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94FJDwql6ezf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}